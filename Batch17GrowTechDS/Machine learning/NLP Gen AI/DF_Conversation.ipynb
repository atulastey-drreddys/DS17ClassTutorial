{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "200d2e96",
   "metadata": {},
   "source": [
    "# Project Title\n",
    "Chat with Dataframe using GEMINI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "122b01a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\GrowTech\\Desktop\\Data Science 16\\Batch17GrowTechDS\\Machine learning\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e02a8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Configuration\n",
    "gemini_api = \"AIzaSyAYRSbisbijk-vcJ6CIhf1Ytf4RyJJOaX0\"\n",
    "genai.configure(api_key=gemini_api)\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f98ad58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "\n",
    "def load_data():\n",
    "    return pd.read_csv(\"Breast Cancer Winscoin.csv\")\n",
    "\n",
    "df = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ac380f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "316e5660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_gemini(query,df):\n",
    "    prompt = f\"\"\" \n",
    "                You are my personal AI Assistant that help\n",
    "                  me to analyze the following dataset\n",
    "        {df.head().to_string()}\n",
    "    \n",
    "    User Query : {query}\n",
    "    \"\"\"\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text if response else \"Sorry i could'nt process that request\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09164aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response The provided dataset appears to be related to breast cancer diagnosis, with features likely representing various measurements of cell nuclei.  Let's break down a descriptive analysis:\n",
      "\n",
      "**1. Data Overview:**\n",
      "\n",
      "* **Variables:** The dataset contains a mix of categorical and numerical variables.\n",
      "    * **Categorical:** `diagnosis` (M = malignant, B = benign). This is the target variable we're likely trying to predict.\n",
      "    * **Numerical:**  The remaining columns represent various measurements (radius, texture, perimeter, area, smoothness, compactness, concavity, concave points, symmetry, fractal dimension) at different scales (mean, standard error (se), worst).\n",
      "\n",
      "* **Missing Values:** There are missing values in the `Unnamed: 32` column.  This column appears to be empty and should likely be dropped from the analysis.\n",
      "\n",
      "* **Data Size:**  The snippet shows the first five rows, but we need the full dataset size to provide a complete analysis.\n",
      "\n",
      "\n",
      "**2. Descriptive Statistics (for Numerical Variables):**\n",
      "\n",
      "To get a good understanding, we need to calculate descriptive statistics for each numerical column (ignoring `Unnamed: 32`):\n",
      "\n",
      "* **Measures of Central Tendency:** Mean, Median, Mode (though mode is less relevant for continuous data). This will tell us the typical values for each feature.\n",
      "* **Measures of Dispersion:** Standard Deviation, Variance, Range, Interquartile Range (IQR). These measures indicate the spread or variability of the data.  High standard deviation indicates more variability.\n",
      "* **Percentiles:**  25th, 50th (median), and 75th percentiles provide further insight into data distribution and identify potential outliers.\n",
      "* **Skewness and Kurtosis:** These describe the shape of the distribution.  Skewness measures asymmetry, while kurtosis measures the \"tailedness\".\n",
      "\n",
      "**Example (Illustrative, requires full dataset calculation):**\n",
      "\n",
      "Let's say we calculate the mean and standard deviation for `radius_mean`:\n",
      "\n",
      "* Mean radius_mean:  14.12\n",
      "* Standard deviation radius_mean:  3.52\n",
      "\n",
      "This would suggest an average radius of 14.12 with a considerable amount of variation (3.52 units) around the average.  Similar calculations would need to be done for all the numerical features.\n",
      "\n",
      "\n",
      "**3. Analysis of Categorical Variable (`diagnosis`):**\n",
      "\n",
      "* **Frequency Distribution:**  We need to count the number of malignant (M) and benign (B) cases to understand the class distribution. This will help determine if the dataset is balanced or imbalanced.  An imbalanced dataset may require special handling techniques in modeling.\n",
      "\n",
      "* **Cross-tabulation:**  We can cross-tabulate `diagnosis` with other variables (if needed for further analysis). For example, we could see if certain ranges of `radius_mean` are more associated with malignant cases.\n",
      "\n",
      "\n",
      "**4. Data Visualization:**\n",
      "\n",
      "Visualizations would significantly enhance the understanding of the data:\n",
      "\n",
      "* **Histograms:** To show the distribution of each numerical feature.\n",
      "* **Box plots:**  To visualize the central tendency, dispersion, and potential outliers for each numerical feature.\n",
      "* **Scatter plots:**  To explore relationships between pairs of numerical features.  For instance, plotting `radius_mean` vs. `area_mean` might reveal a strong positive correlation.\n",
      "* **Bar charts:** To display the frequency distribution of the `diagnosis` variable.\n",
      "\n",
      "\n",
      "**5.  Addressing Missing Values:**\n",
      "\n",
      "The `Unnamed: 32` column needs to be handled.  Since it's completely empty, the simplest solution is to drop this column entirely.\n",
      "\n",
      "\n",
      "**In summary:** A complete descriptive analysis requires computing the descriptive statistics mentioned above and creating appropriate visualizations using the full dataset.  This analysis will provide insights into the characteristics of the data, relationships between variables, and help inform the choice of appropriate machine learning models for prediction (if that is the goal).  Software like R or Python (with libraries like pandas and matplotlib/seaborn) are well-suited for performing these tasks.\n",
      "\n",
      "response The shape of the dataset is (569, 33).  There are 569 rows and 33 columns.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_query = input(\"Ask a question about the dataset or type exit to quit\")\n",
    "    if user_query.lower() == 'exit':\n",
    "        break\n",
    "    response = ask_gemini(user_query,df)\n",
    "    print(\"response\",response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a07e2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
